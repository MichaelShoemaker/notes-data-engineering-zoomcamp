{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f28dc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required Imports\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd05edfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gary/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ca0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05fc8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 - Get Version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74719c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-24 18:13:58--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.72.60\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.72.60|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 699.83M  6.48MB/s    in 1m 41s  \n",
      "\n",
      "2022-02-24 18:15:40 (6.92 MB/s) - ‘fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download Dataset\n",
    "#!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553ffe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fhvhv_tripdata_2021-02.csv  'HomeWork Week5.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "#Check file\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73236237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gzip file\n",
    "!gzip fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17d2ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 04_pyspark.ipynb\t\t head.csv\r\n",
      " de-engineering-spark.ipynb\t'HomeWork Week5.ipynb'\r\n",
      " fhvhv_tripdata_2021-02.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "#Check gzip was successful\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3de7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read first 1000 rows in to get schema info\n",
    "df_pandas = pd.read_csv('fhvhv_tripdata_2021-02.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "634c4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(SR_Flag,DoubleType,true)))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the schema\n",
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ed39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to help make schema more readable\n",
    "def formatSchema(frame):\n",
    "    ip = str(frame).split('StructField')\n",
    "    print('StructType(')\n",
    "    for i in ip:\n",
    "        if '(' in i and ')' in i:\n",
    "            if ')))' in i:\n",
    "                i=i.replace(')))',')')\n",
    "            print(f\"    StructField {i}\")\n",
    "    print(')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60f0c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(\n",
      "    StructField (hvfhs_license_num,StringType,true),\n",
      "    StructField (dispatching_base_num,StringType,true),\n",
      "    StructField (pickup_datetime,StringType,true),\n",
      "    StructField (dropoff_datetime,StringType,true),\n",
      "    StructField (PULocationID,LongType,true),\n",
      "    StructField (DOLocationID,LongType,true),\n",
      "    StructField (SR_Flag,DoubleType,true)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Print out schema with adjustments\n",
    "formatSchema(spark.createDataFrame(df_pandas).schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364dec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create schema for fhv data\n",
    "fhv_schema = types.StructType([\n",
    "    types.StructField (\"hvfhs_license_num\",types.StringType(),True),\n",
    "    types.StructField (\"dispatching_base_num\",types.StringType(),True),\n",
    "    types.StructField (\"pickup_datetime\",types.TimestampType(),True),\n",
    "    types.StructField (\"dropoff_datetime\",types.TimestampType(),True),\n",
    "    types.StructField (\"PULocationID\",types.LongType(),True),\n",
    "    types.StructField (\"DOLocationID\",types.LongType(),True),\n",
    "    types.StructField (\"SR_Flag\",types.DoubleType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cba72678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:10:40</td>\n",
       "      <td>2021-02-01 00:21:09</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:27:23</td>\n",
       "      <td>2021-02-01 00:44:01</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-01 00:28:38</td>\n",
       "      <td>2021-02-01 00:38:27</td>\n",
       "      <td>39</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-02-01 00:43:37</td>\n",
       "      <td>2021-02-01 01:23:20</td>\n",
       "      <td>91</td>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2021-02-01 00:08:42</td>\n",
       "      <td>2021-02-01 00:17:57</td>\n",
       "      <td>126</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num      pickup_datetime  \\\n",
       "0            HV0003               B02764  2021-02-01 00:10:40   \n",
       "1            HV0003               B02764  2021-02-01 00:27:23   \n",
       "2            HV0005               B02510  2021-02-01 00:28:38   \n",
       "3            HV0005               B02510  2021-02-01 00:43:37   \n",
       "4            HV0003               B02872  2021-02-01 00:08:42   \n",
       "\n",
       "      dropoff_datetime  PULocationID  DOLocationID  SR_Flag  \n",
       "0  2021-02-01 00:21:09            35            39      NaN  \n",
       "1  2021-02-01 00:44:01            39            35      NaN  \n",
       "2  2021-02-01 00:38:27            39            91      NaN  \n",
       "3  2021-02-01 01:23:20            91           228      NaN  \n",
       "4  2021-02-01 00:17:57           126           250      NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that there are actually headers\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9ff0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pyspark dataframe\n",
    "df = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79c9a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11613942"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get record count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5b038a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repartition dataframe\n",
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efa2f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make directory for parquet files\n",
    "#This was not needed\n",
    "!mkdir fhvh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431f0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check schema is correct\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60abd7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Write parquet files to directory\n",
    "df.write.parquet('fhvh_data/',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16131efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220M\tfhvh_data/\r\n"
     ]
    }
   ],
   "source": [
    "#Get total parquet file size\n",
    "!du -sh fhvh_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b976ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data from parquet files\n",
    "df = spark.read.parquet('fhvh_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69f411e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11613942"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check record count matches original\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b0fe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register temp table\n",
    "df.registerTempTable('fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca9ed38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of trips on 2/15/2021\n",
    "df_trips = spark.sql(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM fhv\n",
    "WHERE date(pickup_datetime) = '2021-02-15'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1c7e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  367170|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "596a8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_trip = spark.sql(\"\"\"\n",
    "SELECT max(unix_timestamp(dropoff_datetime) -unix_timestamp(pickup_datetime)) as diff\n",
    "FROM fhv\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ada4d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| diff|\n",
      "+-----+\n",
      "|75540|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longest_trip.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36b0d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest = spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM fhv\n",
    "WHERE unix_timestamp(dropoff_datetime) -unix_timestamp(pickup_datetime) = (SELECT max(unix_timestamp(dropoff_datetime) -unix_timestamp(pickup_datetime)) as diff\n",
    "FROM fhv)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24a0b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2021-02-11 13:40:44|2021-02-12 10:39:44|         247|          41|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19601c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_dispatch = spark.sql(\"\"\"\n",
    "SELECT dispatching_base_num\n",
    ",count(*) as Cnt\n",
    "FROM fhv\n",
    "GROUP BY dispatching_base_num\n",
    "ORDER BY Cnt Desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9773e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|    Cnt|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "|              B02869| 429720|\n",
      "|              B02887| 322331|\n",
      "|              B02871| 312364|\n",
      "|              B02864| 311603|\n",
      "|              B02866| 311089|\n",
      "|              B02878| 305185|\n",
      "|              B02682| 303255|\n",
      "|              B02617| 274510|\n",
      "|              B02883| 251617|\n",
      "|              B02884| 244963|\n",
      "|              B02882| 232173|\n",
      "|              B02876| 215693|\n",
      "|              B02879| 210137|\n",
      "|              B02867| 200530|\n",
      "|              B02877| 198938|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_freq_dispatch.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b04125eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-26 17:50:09--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.228.136\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.228.136|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-26 17:50:09 (72.0 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28a76964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 04_pyspark.ipynb\t\t head.csv\r\n",
      " de-engineering-spark.ipynb\t'HomeWork Week5.ipynb'\r\n",
      " fhvh_data\t\t\t taxi+_zone_lookup.csv\r\n",
      " fhvhv_tripdata_2021-02.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5082dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3d4c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 04_pyspark.ipynb\t\t head.csv\r\n",
      " de-engineering-spark.ipynb\t'HomeWork Week5.ipynb'\r\n",
      " fhvh_data\t\t\t taxi+_zone_lookup.csv.gz\r\n",
      " fhvhv_tripdata_2021-02.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f73845ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi+_zone_lookup.csv.gz',nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8669c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(\n",
      "    StructField (LocationID,LongType,true),\n",
      "    StructField (Borough,StringType,true),\n",
      "    StructField (Zone,StringType,true),\n",
      "    StructField (service_zone,StringType,true)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "formatSchema(spark.createDataFrame(df_zones).schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bad5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_schema = types.StructType([\n",
    "    types.StructField (\"LocationID\",types.LongType(),True),\n",
    "    types.StructField (\"Borough\",types.StringType(),True),\n",
    "    types.StructField (\"Zone\",types.StringType(),True),\n",
    "    types.StructField (\"service_zone\",types.StringType(),True)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5814eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_zones = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(zones_schema) \\\n",
    "    .csv('taxi+_zone_lookup.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "920e5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_zones = spark_zones.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4cd97f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_zones.write.parquet('zone_data/',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "391d11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read.parquet('zone_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "556046e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|       127|    Manhattan|              Inwood|   Boro Zone|\n",
      "|       252|       Queens|          Whitestone|   Boro Zone|\n",
      "|       104|    Manhattan|Governor's Island...| Yellow Zone|\n",
      "|       206|Staten Island|Saint George/New ...|   Boro Zone|\n",
      "|       233|    Manhattan| UN/Turtle Bay South| Yellow Zone|\n",
      "|       119|        Bronx|          Highbridge|   Boro Zone|\n",
      "|        62|     Brooklyn| Crown Heights South|   Boro Zone|\n",
      "|       199|        Bronx|       Rikers Island|   Boro Zone|\n",
      "|       107|    Manhattan|            Gramercy| Yellow Zone|\n",
      "|       186|    Manhattan|Penn Station/Madi...| Yellow Zone|\n",
      "|        96|       Queens|Forest Park/Highl...|   Boro Zone|\n",
      "|       138|       Queens|   LaGuardia Airport|    Airports|\n",
      "|       244|    Manhattan|Washington Height...|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        86|       Queens|        Far Rockaway|   Boro Zone|\n",
      "|       110|Staten Island|    Great Kills Park|   Boro Zone|\n",
      "|       235|        Bronx|University Height...|   Boro Zone|\n",
      "|       239|    Manhattan|Upper West Side S...| Yellow Zone|\n",
      "|       122|       Queens|              Hollis|   Boro Zone|\n",
      "|       171|       Queens|  Murray Hill-Queens|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "86f9084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d0f3ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02872|2021-02-08 14:44:38|2021-02-08 15:15:00|         129|          98|   null|\n",
      "|           HV0003|              B02887|2021-02-07 08:19:00|2021-02-07 08:32:43|         188|          35|   null|\n",
      "|           HV0005|              B02510|2021-02-03 07:58:56|2021-02-03 08:22:21|          75|          50|   null|\n",
      "|           HV0003|              B02869|2021-02-13 09:18:39|2021-02-13 09:41:07|          61|         162|   null|\n",
      "|           HV0003|              B02872|2021-02-06 15:55:43|2021-02-06 16:50:06|         125|         220|   null|\n",
      "|           HV0005|              B02510|2021-02-12 23:29:09|2021-02-12 23:44:24|          39|          35|   null|\n",
      "|           HV0003|              B02878|2021-02-25 15:09:08|2021-02-25 15:23:12|         234|         237|   null|\n",
      "|           HV0003|              B02765|2021-02-04 20:23:29|2021-02-04 20:35:55|         144|          97|   null|\n",
      "|           HV0003|              B02878|2021-02-16 07:58:36|2021-02-16 08:57:38|         241|         189|   null|\n",
      "|           HV0003|              B02764|2021-02-16 09:09:42|2021-02-16 09:43:05|          25|         263|   null|\n",
      "|           HV0003|              B02764|2021-02-08 13:46:29|2021-02-08 13:59:04|          71|          62|   null|\n",
      "|           HV0003|              B02877|2021-02-15 16:51:03|2021-02-15 17:07:11|          21|         210|   null|\n",
      "|           HV0005|              B02510|2021-02-20 20:27:46|2021-02-20 20:43:55|          37|          61|   null|\n",
      "|           HV0005|              B02510|2021-02-16 14:53:10|2021-02-16 15:30:25|         174|         193|   null|\n",
      "|           HV0003|              B02871|2021-02-28 17:07:50|2021-02-28 17:12:10|         123|         210|   null|\n",
      "|           HV0003|              B02887|2021-02-08 05:30:48|2021-02-08 05:41:03|         141|         226|   null|\n",
      "|           HV0003|              B02866|2021-02-17 17:21:19|2021-02-17 17:32:16|         161|          68|   null|\n",
      "|           HV0005|              B02510|2021-02-25 00:40:10|2021-02-25 00:47:28|          90|         164|   null|\n",
      "|           HV0003|              B02835|2021-02-14 00:25:05|2021-02-14 00:32:59|          37|         256|   null|\n",
      "|           HV0003|              B02869|2021-02-11 19:05:43|2021-02-11 19:15:29|         231|          45|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb4162ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = spark.sql(\"\"\"\n",
    "with mostcomm as(SELECT fhv.PULocationID\n",
    ",fhv.DOLocationID\n",
    ",COUNT(*) as Count\n",
    "FROM fhv\n",
    "GROUP BY PULocationID, DOLocationID\n",
    "ORDER BY Count Desc\n",
    "LIMIT 1)\n",
    "\n",
    "\n",
    "SELECT a.Zone\n",
    ",b.Zone\n",
    "FROM mostcomm inner join zones a\n",
    "on PULocationID = a.LocationID\n",
    "inner join zones b\n",
    "on DOLocationID = b.LocationID\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2419a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|         Zone|         Zone|\n",
      "+-------------+-------------+\n",
      "|East New York|East New York|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 53:=================================================>    (184 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "most_common.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cabc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
